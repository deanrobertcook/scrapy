name: ci

on:
  push:
    branches:
      - 'master'

jobs:
  scrapyd_image:
    runs-on: ubuntu-latest
    steps:
      - name: Set up Docker Buildx
        id: buildx
        uses: docker/setup-buildx-action@v1

      - name: checkout repo content
        uses: actions/checkout@v2 

      - name: Login to DockerHub
        uses: docker/login-action@v1 
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_ACCESS_TOKEN }}

      - name: Extract metadata (tags, labels) for Docker
        id: meta
        uses: docker/metadata-action@98669ae865ea3cffbcbaa878cf57c20bbf1c6c38
        with:
          images: deanrobertcook/quotes-scrapyd

      # We could use these variables to build the docker tag ourselves, but 
      # I'll leave both steps here for now as a demonstration
      # TODO: It'd be worth learning more about Go templates to add a bit of logic
      # e.g. ${{ if steps.vars.outputs.branch == 'master' 'prod' else 'staging' }}, if that's
      # possible. 
      - name: Declare build variables to be passed
        id: vars
        shell: bash
        run: |
          echo "##[set-output name=branch;]$(echo ${GITHUB_REF#refs/heads/})"
          echo "::set-output name=sha_short::$(git rev-parse --short HEAD)"

      - name: Build and push scrapyd image
        id: docker_build
        uses: docker/build-push-action@v2
        with:
          file: scrapyd/Dockerfile
          build-args: |
            RELEASE_VERSION=${{ steps.vars.outputs.sha_short }}
            ENVIRONMENT=${{ steps.vars.outputs.branch }}
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          cache-from: type=registry,ref=deanrobertcook/quotes-scrapyd:buildcache
          cache-to: type=registry,ref=deanrobertcook/quotes-scrapyd:buildcache,mode=max

      - name: Run scrapyd on the droplet
        uses: appleboy/ssh-action@master
        with:
          host: ${{ secrets.DROPLET_HOST }}
          username: ${{ secrets.DROPLET_USERNAME }}
          password: ${{ secrets.DROPLET_PASSWORD }}
          # Removing the image is a bit of a hack, since the droplet's Docker can't know if a locally
          # stored image is out of date from latest version on the Dockerhub repo. Just remove and 
          # re-download for now. 
          # 
          # I can't for the life of me figure out how multiline commands work here. 
          # It should work: https://github.com/appleboy/ssh-action/issues/75
          script: |
            docker pull ${{ steps.meta.outputs.tags }}
            for id in $(docker ps -q)
            do
                if [[ $(docker port "${id}") == *"6800"* ]]; then
                    echo "stopping container ${id}"
                    docker stop "${id}"
                fi
            done
            docker run -d -p 6800:6800 -e USERNAME=${{ secrets.SCRAPYD_DEPLOYER_USERNAME }} -e PASSWORD=${{ secrets.SCRAPYD_DEPLOYER_PW }} -v scrapyd:/scrapyd -v /usr/local/lib/python3.7/dist-packages ${{ steps.meta.outputs.tags }}

      - name: setup python
        uses: actions/setup-python@v2
        with:
          python-version: 3.8 

      - uses: actions/cache@v2
      with:
        path: ~/.cache/pip
        key: scrapyd-deploy-1.2.0a1

      - name: Deploy spiders
        run: |
          sed -i 's/secrets.SCRAPYD_DEPLOYER_USERNAME/${{ secrets.SCRAPYD_DEPLOYER_USERNAME }}/g' scrapy.cfg
          sed -i 's/secrets.SCRAPYD_DEPLOYER_PW/${{ secrets.SCRAPYD_DEPLOYER_PW }}/g' scrapy.cfg
          python -m pip install --upgrade pip
          pip install --upgrade --upgrade-strategy eager scrapy==2.4.0 scrapyd-client==1.2.0a1 -e .
          scrapyd-deploy
